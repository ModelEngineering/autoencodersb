{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a02677-cd2e-40cf-a5e9-7004ac194384",
   "metadata": {},
   "source": [
    "# NN BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4307cd29-ea44-44f7-a388-dd6808db5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945fd5d-1837-465f-8b35-3205c026d748",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6f130d52-78b0-46d3-be84-656af8a3b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "def calculateOutput(layer:torch.nn.modules.linear.Linear, input_arr:np.ndarray,\n",
    "            is_relu=True)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the output from a liner layer.\n",
    "       N - number of samples\n",
    "       O - number of outputs\n",
    "       I - number of inputs\n",
    "\n",
    "    Args:\n",
    "        layer: Linear layer\n",
    "        input_arr: np.Array (N X I)\n",
    "\n",
    "    Returs\n",
    "        np.array: N X O\n",
    "    \"\"\"\n",
    "    num_input = layer.in_features\n",
    "    num_output = layer.out_features\n",
    "    # Get the weights\n",
    "    A_tensor = list(layer.named_parameters())[0][1]\n",
    "    #\n",
    "    b_tensor = torch.detach((list(layer.named_parameters())[1][1])).clone()\n",
    "    #\n",
    "    weight_product_tensor = A_tensor.detach().matmul(input_arr)  # rows are outputs, columns are samples\n",
    "    result = weight_product_tensor + b_tensor.reshape(num_output, 1)\n",
    "    if is_relu:\n",
    "        result = nn.ReLU()(result)\n",
    "    return result.detach().numpy().T\n",
    "    \n",
    "######### TESTS\n",
    "# Setup\n",
    "test_data_arr = np.array([ [1, 2],\n",
    "                      [10, 20],\n",
    "                      [100, 200],\n",
    "                         ], dtype=float)\n",
    "input_arr = torch.tensor(test_data_arr.T).to(torch.float32)\n",
    "layer = nn.Linear(2, 4)\n",
    "layer_tensor = layer(input_arr.T).detach()\n",
    "#\n",
    "result = calculateOutput(layer, input_arr, is_relu=False)\n",
    "assert(np.sum((result - layer_tensor.numpy())**2) <= 1e-5)\n",
    "# With relu\n",
    "result = calculateOutput(layer, input_arr, is_relu=True)\n",
    "assert(np.sum((result - nn.ReLU()(layer_tensor).numpy())**2) <= 1e-5)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1845aa8d-ac8b-4b60-aa32-e9f98b5c9279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'in_features',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'out_features',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05c196-294c-438c-a36f-7193a6dcd111",
   "metadata": {},
   "source": [
    "# Get GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5f33a9-9c42-4a01-8d53-c34ee7d605b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919de67e-4a43-4c2e-b04d-46703211670a",
   "metadata": {},
   "source": [
    "# Basic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a60e611-23cb-497c-b97c-cd453e2e5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fb256b-fd7f-4057-929b-49e90f57c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a1be4c-ca92-436b-a3f7-06e6e20e05d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([3], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 2, 1, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e812a1c8-ae46-4d55-9fdf-8e84bda144f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1628, 0.1750, 0.2248, 0.2270, 0.2103]], device='mps:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be9a032d-a2e2-4f6b-bdcd-2d019027179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], device='mps:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60658901-368c-4748-ab58-1cce94b8424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_relu_stack.0.weight', 3),\n",
       " ('linear_relu_stack.0.bias', 3),\n",
       " ('linear_relu_stack.2.weight', 4),\n",
       " ('linear_relu_stack.2.bias', 4),\n",
       " ('linear_relu_stack.4.weight', 5),\n",
       " ('linear_relu_stack.4.bias', 5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_parameters = list(model.named_parameters())\n",
    "[(x[0], len(x[1])) for x in named_parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040e9a4-079f-4def-9e29-7cb72ec7d475",
   "metadata": {},
   "source": [
    "# NN Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f979f-0312-4df9-ba3b-ff445356c6b8",
   "metadata": {},
   "source": [
    "NN operation is a matrix multiplication. ReLU provides thresholding.\n",
    "One challenge is managing the inputs to and outputs from a neuron."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
