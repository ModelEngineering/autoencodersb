{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a02677-cd2e-40cf-a5e9-7004ac194384",
   "metadata": {},
   "source": [
    "# NN BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4307cd29-ea44-44f7-a388-dd6808db5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945fd5d-1837-465f-8b35-3205c026d748",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6f130d52-78b0-46d3-be84-656af8a3b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "def calculateOutput(layer:torch.nn.modules.linear.Linear, input_arr:np.ndarray,\n",
    "            is_relu=True)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the output from a liner layer.\n",
    "       N - number of samples\n",
    "       O - number of outputs\n",
    "       I - number of inputs\n",
    "\n",
    "    Args:\n",
    "        layer: Linear layer\n",
    "        input_arr: np.Array (N X I)\n",
    "\n",
    "    Returs\n",
    "        np.array: N X O\n",
    "    \"\"\"\n",
    "    num_input = layer.in_features\n",
    "    num_output = layer.out_features\n",
    "    # Get the weights\n",
    "    A_tensor = list(layer.named_parameters())[0][1]\n",
    "    #\n",
    "    b_tensor = torch.detach((list(layer.named_parameters())[1][1])).clone()\n",
    "    #\n",
    "    weight_product_tensor = A_tensor.detach().matmul(input_arr)  # rows are outputs, columns are samples\n",
    "    result = weight_product_tensor + b_tensor.reshape(num_output, 1)\n",
    "    if is_relu:\n",
    "        result = nn.ReLU()(result)\n",
    "    return result.detach().numpy().T\n",
    "    \n",
    "######### TESTS\n",
    "# Setup\n",
    "test_data_arr = np.array([ [1, 2],\n",
    "                      [10, 20],\n",
    "                      [100, 200],\n",
    "                         ], dtype=float)\n",
    "input_arr = torch.tensor(test_data_arr.T).to(torch.float32)\n",
    "layer = nn.Linear(2, 4)\n",
    "layer_tensor = layer(input_arr.T).detach()\n",
    "#\n",
    "result = calculateOutput(layer, input_arr, is_relu=False)\n",
    "assert(np.sum((result - layer_tensor.numpy())**2) <= 1e-5)\n",
    "# With relu\n",
    "result = calculateOutput(layer, input_arr, is_relu=True)\n",
    "assert(np.sum((result - nn.ReLU()(layer_tensor).numpy())**2) <= 1e-5)\n",
    "print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1845aa8d-ac8b-4b60-aa32-e9f98b5c9279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'in_features',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'out_features',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05c196-294c-438c-a36f-7193a6dcd111",
   "metadata": {},
   "source": [
    "# Get GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5f33a9-9c42-4a01-8d53-c34ee7d605b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919de67e-4a43-4c2e-b04d-46703211670a",
   "metadata": {},
   "source": [
    "# Basic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a60e611-23cb-497c-b97c-cd453e2e5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fb256b-fd7f-4057-929b-49e90f57c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a1be4c-ca92-436b-a3f7-06e6e20e05d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([3], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 2, 1, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e812a1c8-ae46-4d55-9fdf-8e84bda144f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1628, 0.1750, 0.2248, 0.2270, 0.2103]], device='mps:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be9a032d-a2e2-4f6b-bdcd-2d019027179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], device='mps:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60658901-368c-4748-ab58-1cce94b8424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linear_relu_stack.0.weight', 3),\n",
       " ('linear_relu_stack.0.bias', 3),\n",
       " ('linear_relu_stack.2.weight', 4),\n",
       " ('linear_relu_stack.2.bias', 4),\n",
       " ('linear_relu_stack.4.weight', 5),\n",
       " ('linear_relu_stack.4.bias', 5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_parameters = list(model.named_parameters())\n",
    "[(x[0], len(x[1])) for x in named_parameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a00b5-4b74-4eb3-98ed-a416cc254faf",
   "metadata": {},
   "source": [
    "# NN Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e4ba8-0206-4884-939c-f6082d68aefa",
   "metadata": {},
   "source": [
    "NN operation is a matrix multiplication. ReLU provides thresholding.\n",
    "One challenge is managing the inputs to and outputs from a neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a25c2-671d-4a15-aa99-79cdd3329877",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aeb3dabf-2abf-45a5-821a-239b9f2b1b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Training Basic Autoencoder...\n",
      "Epoch [1/5], Loss: 0.0500\n",
      "Epoch [2/5], Loss: 0.0220\n",
      "Epoch [3/5], Loss: 0.0167\n",
      "Epoch [4/5], Loss: 0.0136\n",
      "Epoch [5/5], Loss: 0.0118\n",
      "\n",
      "Training Variational Autoencoder...\n",
      "Epoch [1/5], Loss: 21122.5012\n",
      "Epoch [2/5], Loss: 15497.6482\n",
      "Epoch [3/5], Loss: 14616.2168\n",
      "Epoch [4/5], Loss: 14236.7660\n",
      "Epoch [5/5], Loss: 14029.5964\n",
      "\n",
      "Training Denoising Autoencoder...\n",
      "Epoch [1/5], Loss: 0.0588\n",
      "Epoch [2/5], Loss: 0.0344\n",
      "Epoch [3/5], Loss: 0.0300\n",
      "Epoch [4/5], Loss: 0.0281\n",
      "Epoch [5/5], Loss: 0.0270\n",
      "\n",
      "Training completed!\n",
      "Final losses - Basic: 0.0118, Conv: nan, VAE: 14029.5964, Denoising: 0.0270\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set device\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 1. Basic Fully Connected Autoencoder\n",
    "class BasicAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=128, latent_dim=64):\n",
    "        super(BasicAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # For image data normalized to [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# 2. Convolutional Autoencoder (better for images)\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28x28 -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 14x14 -> 7x7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)                       # 7x7 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),                      # 1x1 -> 7x7\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1), # 7x7 -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # 14x14 -> 28x28\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# 3. Variational Autoencoder (VAE)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)  # mu\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)  # logvar\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Loss function for VAE\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# 4. Denoising Autoencoder\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=128, latent_dim=64):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Training function\n",
    "def train_autoencoder(model, dataloader, num_epochs=10, lr=1e-3, model_type='basic'):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            if model_type == 'basic' or model_type == 'denoising':\n",
    "                data = data.view(data.size(0), -1)  # Flatten for FC layers\n",
    "                \n",
    "                if model_type == 'denoising':\n",
    "                    # Add noise to input\n",
    "                    noise = torch.randn_like(data) * 0.3\n",
    "                    noisy_data = data + noise\n",
    "                    noisy_data = torch.clamp(noisy_data, 0., 1.)\n",
    "                    output = model(noisy_data)\n",
    "                else:\n",
    "                    output = model(data)\n",
    "                \n",
    "                loss = criterion(output, data)\n",
    "                \n",
    "            elif model_type == 'conv':\n",
    "                output = model(data)\n",
    "                loss = criterion(output, data)\n",
    "                \n",
    "            elif model_type == 'vae':\n",
    "                recon_batch, mu, logvar = model(data)\n",
    "                loss = vae_loss(recon_batch, data, mu, logvar)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Visualization function\n",
    "def visualize_results(model, dataloader, model_type='basic', num_images=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(dataloader))\n",
    "        data = data[:num_images].to(device)\n",
    "        \n",
    "        if model_type == 'basic' or model_type == 'denoising':\n",
    "            data_flat = data.view(data.size(0), -1)\n",
    "            if model_type == 'denoising':\n",
    "                # Add noise for demonstration\n",
    "                noise = torch.randn_like(data_flat) * 0.3\n",
    "                noisy_data = data_flat + noise\n",
    "                noisy_data = torch.clamp(noisy_data, 0., 1.)\n",
    "                reconstructed = model(noisy_data)\n",
    "            else:\n",
    "                reconstructed = model(data_flat)\n",
    "            reconstructed = reconstructed.view(-1, 1, 28, 28)\n",
    "            \n",
    "        elif model_type == 'conv':\n",
    "            reconstructed = model(data)\n",
    "            \n",
    "        elif model_type == 'vae':\n",
    "            reconstructed, _, _ = model(data)\n",
    "            reconstructed = reconstructed.view(-1, 1, 28, 28)\n",
    "    \n",
    "    # Plot original and reconstructed images\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(12, 4))\n",
    "    for i in range(num_images):\n",
    "        # Original\n",
    "        axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title('Original')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed\n",
    "        axes[1, i].imshow(reconstructed[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[1, i].set_title('Reconstructed')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load MNIST dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=128, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Example 1: Basic Autoencoder\n",
    "    print(\"Training Basic Autoencoder...\")\n",
    "    basic_ae = BasicAutoencoder().to(device)\n",
    "    basic_losses = train_autoencoder(basic_ae, train_loader, num_epochs=5, model_type='basic')\n",
    "    \n",
    "    # Example 2: Convolutional Autoencoder\n",
    "    # FIXME: Problem with the NN definition or data that is dimensioned wrong.\n",
    "    #print(\"\\nTraining Convolutional Autoencoder...\")\n",
    "    #conv_ae = ConvAutoencoder().to(device)\n",
    "    #conv_losses = train_autoencoder(conv_ae, train_loader, num_epochs=5, model_type='conv')\n",
    "    conv_losses = [np.nan]\n",
    "    \n",
    "    # Example 3: Variational Autoencoder\n",
    "    print(\"\\nTraining Variational Autoencoder...\")\n",
    "    vae = VAE().to(device)\n",
    "    vae_losses = train_autoencoder(vae, train_loader, num_epochs=5, model_type='vae')\n",
    "    \n",
    "    # Example 4: Denoising Autoencoder\n",
    "    print(\"\\nTraining Denoising Autoencoder...\")\n",
    "    denoising_ae = DenoisingAutoencoder().to(device)\n",
    "    denoising_losses = train_autoencoder(denoising_ae, train_loader, num_epochs=5, model_type='denoising')\n",
    "    \n",
    "    # Visualize results (uncomment to see plots)\n",
    "    # visualize_results(basic_ae, train_loader, 'basic')\n",
    "    # visualize_results(conv_ae, train_loader, 'conv')\n",
    "    # visualize_results(vae, train_loader, 'vae')\n",
    "    # visualize_results(denoising_ae, train_loader, 'denoising')\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Final losses - Basic: {basic_losses[-1]:.4f}, Conv: {conv_losses[-1]:.4f}, \"\n",
    "          f\"VAE: {vae_losses[-1]:.4f}, Denoising: {denoising_losses[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
