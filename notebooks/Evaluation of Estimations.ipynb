{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2888e14a-f582-4f7a-b061-628c58a5d787",
   "metadata": {},
   "source": [
    "# EVALUATION OF ESTIMATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cec2166-5d24-46f3-b44d-c46020ca6795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iplane.interpolator import Interpolator  # type: ignore\n",
    "from iplane.random_mixture_collection import PCollectionMixture, DCollectionMixture  # type: ignore\n",
    "from iplane.random_mixture import RandomMixture  # type: ignore\n",
    "from iplane.random_empirical import RandomEmpirical  # type: ignore\n",
    "import iplane.constants as cn  # type: ignore\n",
    "\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt  # type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0660f-9192-4912-a570-7a6c36ad018a",
   "metadata": {},
   "source": [
    "# Accuracy of Empirical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6445e-9968-419e-a82c-56a1cb30365b",
   "metadata": {},
   "source": [
    "The accuracy of an empirical estimation depends on :\n",
    "1. Number of samples used to construct the empirical distribution\n",
    "2. Number of dimensions of the variate\n",
    "3. How samples are selected to assess accuracy\n",
    "4. For a guassian, covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7559a241-14d0-47f5-bdeb-f03a57cbfb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(num_sample=100, num_dimension=5, variance=1, covariance=0, mean_absolute_error=np.float64(0.013598213469307745), fraction_evaluated=0.91, sampling_std=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluationResult = namedtuple(\"EvaluationResult\",\n",
    "        [\"num_sample\", \"num_dimension\", \"variance\", \n",
    "         \"covariance\", \"mean_absolute_error\", \"fraction_evaluated\", \"sampling_std\"])\n",
    "def evaluateEmpirical(num_sample:int=100,\n",
    "                      num_dimension:int=2,\n",
    "                      variance:float=4,\n",
    "                      covariance:float=0,\n",
    "                      sampling_std:float=3,\n",
    "                     ) -> EvaluationResult:\n",
    "    # Constants\n",
    "    NUM_ITERATION = 100\n",
    "    # Initializations\n",
    "    mean_arr = np.repeat(0, num_dimension)\n",
    "    covariance_arr = np.repeat(covariance, num_dimension*num_dimension).reshape(num_dimension, num_dimension)\n",
    "    np.fill_diagonal(covariance_arr, variance)\n",
    "    weight_arr = np.array([1.0])\n",
    "    pcollection = PCollectionMixture(\n",
    "        mean_arr=np.array([mean_arr]),\n",
    "        covariance_arr=np.array([covariance_arr]),\n",
    "        weight_arr=weight_arr,\n",
    "    )\n",
    "    random_mixture = RandomMixture()\n",
    "    random_empirical = RandomEmpirical()\n",
    "    sample_arr = random_mixture.generateSample(pcollection, num_sample=num_sample)\n",
    "    _ = random_empirical.estimatePCollection(sample_arr)\n",
    "    cdf = random_empirical.makeCDF(sample_arr)\n",
    "    variate_arr = cdf.variate_arr\n",
    "    cdf_arr = cdf.cdf_arr\n",
    "    #\n",
    "    interpolator = Interpolator( variate_arr=variate_arr, sample_arr=cdf_arr,\n",
    "            is_normalize=True, max_distance=1, size_interpolation_set=5)\n",
    "    errors:list = []\n",
    "    avg_errors:list = []\n",
    "    results:list = []\n",
    "    probabilities:list = []\n",
    "    for _ in range(NUM_ITERATION):\n",
    "        point = np.random.uniform(-sampling_std, sampling_std, (num_dimension,))\n",
    "        if not interpolator.isWithinRange(point):\n",
    "            continue\n",
    "        if num_dimension == 1:\n",
    "            probability = norm.cdf(point, 0, scale=variance**0.5)\n",
    "        else:\n",
    "            probability = multivariate_normal.cdf(point, mean=mean_arr, cov=covariance_arr)  # type: ignore\n",
    "        result = interpolator.predict(point)\n",
    "        if np.isnan(result[0]):\n",
    "            continue\n",
    "        results.append(result[0])\n",
    "        probabilities.append(probability)\n",
    "        errors.append(abs(probability - result[0]))\n",
    "        avg_errors.append(probability - result[0])\n",
    "    evaluation_result = EvaluationResult(\n",
    "        num_sample=num_sample, num_dimension=num_dimension, variance=variance,\n",
    "        mean_absolute_error=np.mean(errors),\n",
    "        fraction_evaluated=len(errors)/NUM_ITERATION,\n",
    "        covariance=covariance,\n",
    "        sampling_std=sampling_std,\n",
    "    )\n",
    "    return evaluation_result\n",
    "\n",
    "# Tests\n",
    "evaluateEmpirical(num_dimension=5, num_sample=100, sampling_std=1, variance=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478315d5-8a3e-4f4c-ba84-eacee92b955a",
   "metadata": {},
   "source": [
    "Evaluations\n",
    "1. Univariate, variance = 1. Heatmap with x,y = sample size, sampline_std. Color is frac succes, mean asolute error\n",
    "2. Do the same for multivariates: 2,4, 8, 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
